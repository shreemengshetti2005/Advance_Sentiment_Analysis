# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NkFLp98PS1Gsab5BvtDFsWQr2RaghqSa
"""

!pip install -q kaggle
from google.colab import files
files.upload()  # Upload your kaggle.json file here

import os
os.makedirs('/root/.kaggle', exist_ok=True)
os.rename('kaggle.json', '/root/.kaggle/kaggle.json')

!kaggle datasets download -d snap/amazon-fine-food-reviews

import zipfile

with zipfile.ZipFile('amazon-fine-food-reviews.zip', 'r') as zip_ref:
    zip_ref.extractall('amazon_fine_food_reviews')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

plt.style.use('ggplot')

import nltk

df= pd.read_csv('amazon_fine_food_reviews/Reviews.csv')

df.head()

df['Text'][3]

df.shape

df=df.head(500)

df.head()

df.shape

df['Score']

ax = df['Score'].value_counts().sort_index().plot(
    kind='bar',
    title='Count of Reviews by Stars',
)
ax.set_xlabel('Review Stars')
ax.set_ylabel('Number of Reviews')

plt.show()

eg=df['Text'][50]
eg

import nltk
nltk.download('punkt_tab')

import nltk
nltk.download('averaged_perceptron_tagger_eng')

import nltk
nltk.download('maxent_ne_chunker_tab')
nltk.download('words')

import nltk
tokens=nltk.word_tokenize(eg)
tokens[:10]

tagged=nltk.pos_tag(tokens)
tagged[:10]

entities =nltk.chunk.ne_chunk(tagged)
entities.pprint()

"""# VADER Sentiment Scoring

VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media. It uses a combination of a sentiment lexicon (a list of words rated for their sentiment intensity) and a set of five generalizable rules that describe the sentiment intensity of a text.

### This uses BOW (Bag of Words):
* Stop words are often removed as part of the preprocessing.
* Each word in the text is scored based on its sentiment from the VADER lexicon, and these scores are combined to get a total sentiment score for the text.
"""

import nltk
nltk.download('vader_lexicon')

from nltk.sentiment.vader import SentimentIntensityAnalyzer
from tqdm.notebook import tqdm

sia = SentimentIntensityAnalyzer()

sia.polarity_scores('I am so happy')

#getting the polarity scores on the entire dataset

res= {}

for i, row in tqdm(df.iterrows(), total=len(df)):
  text = row['Text']
  myid = row['Id']
  res[myid] = sia.polarity_scores(text)

res

pd.DataFrame(res).T

vad = pd.DataFrame(res).T
vad =vad.reset_index().rename(columns={'index':'Id'})
vad = vad.merge(df,how='left')

"""# Adding Roberta model"""

vad.head()

from transformers import AutoTokenizer
from transformers import AutoModelForSequenceClassification
from scipy.special import softmax

MODEL = f"cardiffnlp/twitter-roberta-base-sentiment"
tokenizer = AutoTokenizer.from_pretrained(MODEL)
model = AutoModelForSequenceClassification.from_pretrained(MODEL)

def polarity_scores_roberta(example):
    encoded_text = tokenizer(example, return_tensors='pt')
    output=model(**encoded_text)
    scores=output[0][0].detach().numpy()
    scores=softmax(scores)
    scores_dict = {
        'roberta_neg' : scores[0],
        'roberta_neu' : scores[1],
        'roberta_pos' : scores[2]
    }
    return(scores_dict)

res= {}

for i, row in tqdm(df.iterrows(), total=len(df)):
  try:
      text = row['Text']
      myid = row['Id']
      vader_result = sia.polarity_scores(text)

      vader_result_rename = {}
      for key, value in vader_result.items():
        vader_result_rename[f"vader_{key}"] = value

      roberta_result = polarity_scores_roberta(text)
      both = {**vader_result, **roberta_result}
      res[myid] = both
  except RuntimeError:
      print(f'Broke for id {myid}')

results_df= pd.DataFrame(res).T
results_df = results_df.reset_index().rename(columns={'index':'Id'})
results_df = results_df.merge(df, how='left')

results_df.head()

from transformers import pipeline

user_query= pipeline('sentiment-analysis')

user_query("The flavor was so unexpectedly bold, it was almost off-puttingly delicious!")

user_query("I can't believe how good this is; it's so simple, it feels like I'm cheating!")



user_query("I can't believe how good this is; it's so simple, it feels like I'm cheating!")